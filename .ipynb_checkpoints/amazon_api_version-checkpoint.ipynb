{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import boto3, json, random, re, requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'>' not supported between instances of 'list' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-e00faa50995c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    220\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 222\u001b[1;33m \u001b[0mchoice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtitle_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtitle_message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentiment\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtitle_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprice_string\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    223\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m \u001b[1;31m# Parse the title to see if the first word is a verb or noun\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-e00faa50995c>\u001b[0m in \u001b[0;36mtitle_message\u001b[1;34m(sentiment, title_list, price_string)\u001b[0m\n\u001b[0;32m    202\u001b[0m     \u001b[1;31m# if the market finished up select our random positive message; if there is no pos message, go with a neutral\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mprice_string\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"+\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 204\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpos_index\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    205\u001b[0m             \u001b[0mchoice\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpos_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    206\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mchoice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtitle_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mchoice\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: '>' not supported between instances of 'list' and 'int'"
     ]
    }
   ],
   "source": [
    "# Setting up requests package user agent.\n",
    "\n",
    "\"\"\"\n",
    "Create list of links and titles separately\n",
    "\"\"\"\n",
    "link_list = []\n",
    "title_list = []\n",
    "\n",
    "user_agent = \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/35.0.1916.47 Safari/537.36\"\n",
    "headers = {\"User-Agent\": user_agent}\n",
    "\n",
    "# Scraping from The Dodo\n",
    "dodo_url = \"https://www.thedodo.com/close-to-home\"\n",
    "\n",
    "response = requests.get(dodo_url, headers=headers)\n",
    "dodo_soup = BeautifulSoup(response.content, \"lxml\")\n",
    "\n",
    "\"\"\"\n",
    "We are grabbing 'low hanging fruit' stories on the day.\n",
    "This is done via the 'close to home' page on the site.\n",
    "\"\"\"\n",
    "\n",
    "dodo_list = dodo_soup.findAll(\n",
    "    \"a\", attrs={\"class\": \"double-column-listing__link u-block-link ga-trigger\"}\n",
    ")\n",
    "\n",
    "[link_list.append(i[\"href\"]) for i in dodo_list]\n",
    "\n",
    "for i in dodo_list:\n",
    "    title_list.append(i.find(\"h2\").text.strip())\n",
    "\n",
    "# Huffpost Scrape\n",
    "\n",
    "huff_url = \"https://www.huffpost.com/entertainment/topic/cute-animals\"\n",
    "huff_response = requests.get(huff_url, headers=headers)\n",
    "huff_soup = BeautifulSoup(huff_response.content, \"lxml\")\n",
    "\n",
    "\"\"\"\n",
    "Ditto here. We're just looking for a list of stories \n",
    "that updates roughly daily. \n",
    "\"\"\"\n",
    "\n",
    "huff_list = huff_soup.findAll(\n",
    "    \"a\", attrs={\"class\": \"card__headline card__headline--long\"}\n",
    ")\n",
    "\n",
    "for link in huff_list:\n",
    "    link_list.append(link[\"href\"])\n",
    "\n",
    "for title in huff_list:\n",
    "    title_list.append(title.find(\"h2\").text.strip())\n",
    "\n",
    "\n",
    "# Buzzpaws Scrape\n",
    "\n",
    "url = \"http://www.buzzpaws.com/\"\n",
    "response = requests.get(url, headers=headers)\n",
    "buzz_soup = BeautifulSoup(response.content, \"lxml\")\n",
    "\n",
    "buzz_list = buzz_soup.findAll(\n",
    "    \"div\", attrs={\"class\": \"content-thumb content-list-thumb\"}\n",
    ")\n",
    "\n",
    "for link in buzz_list:\n",
    "    link_list.append(link.find(\"a\")[\"href\"])\n",
    "\n",
    "for title in buzz_list:\n",
    "    title_list.append(title.find(\"a\")[\"title\"])\n",
    "\n",
    "title_list\n",
    "\n",
    "# Analyze sentiment\n",
    "\n",
    "client = boto3.client(\"comprehend\")\n",
    "sentiment = []\n",
    "for sentence in title_list:\n",
    "    sentiment.append(\n",
    "        client.detect_sentiment(Text=sentence, LanguageCode=\"en\")[\"Sentiment\"]\n",
    "    )\n",
    "\n",
    "# Render titles into lower case for later publishing\n",
    "title_list = [x.lower() for x in title_list]\n",
    "\n",
    "# So now we have link_list, sentiment, and title_list in memory\n",
    "\n",
    "# Discover Whether the Market Closed Up or Down on the Day\n",
    "\n",
    "# Reset the user agent and headers\n",
    "user_agent = \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/35.0.1916.47 Safari/537.36\"\n",
    "headers = {\"User-Agent\": user_agent}\n",
    "\n",
    "# We can grab a closing price from Yahoo Finance\n",
    "url = \"https://finance.yahoo.com/quote/^GSPC\"\n",
    "\n",
    "response = requests.get(url, headers=headers)\n",
    "price_soup = BeautifulSoup(response.content, \"lxml\")\n",
    "\n",
    "# Extract the string we want with price information\n",
    "price_text = price_soup.findAll(\"div\", attrs={\"class\": \"D(ib) Mend(20px)\"})[0].text\n",
    "price_string = price_text[price_text.find(\"(\") + 1 : price_text.find(\")\")]\n",
    "\n",
    "\"\"\"\n",
    "Remove the four-digit delta in price, either positive or negative, from the Yahoo Finance\n",
    "string.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def price_format(price_string, price_text):\n",
    "    price_1 = re.sub(\n",
    "        r\"\\+[0-9]{1,2}[^(]*\", \" \", price_text, count=1\n",
    "    )  # + change; count=1 means remove only first instance\n",
    "    price_2 = re.sub(r\"\\-[0-9]{1,2}[^(]*\", \" \", price_text, count=1)  # - change\n",
    "\n",
    "    if price_string[0] == \"+\":  # positive delta\n",
    "        return price_1\n",
    "    else:\n",
    "        return price_2\n",
    "\n",
    "\n",
    "price_text = price_format(price_string, price_text)\n",
    "\n",
    "\n",
    "def price_clean(price_text):\n",
    "    # Remove remaining text\n",
    "    price_text = re.sub(\"[A-z]\", \"\", price_text)\n",
    "    # Remove remaining artifacts\n",
    "    price_text = re.sub(\"[ :]\", \"\", price_text)\n",
    "    price_text = re.sub(\"\\)[0-9]{3}\", \")\", price_text)\n",
    "    # Format the text for Twitter printing\n",
    "    price_text = price_text.replace(\"(\", \"\\n(\").replace(\")\", \")\\n\\n\")\n",
    "    # for some reason the chained replace was not working so it required a second pass, such...\n",
    "    price_text = price_text.replace(\"..\", \"\")\n",
    "    return price_text\n",
    "\n",
    "\n",
    "price_text = price_clean(price_text)\n",
    "\n",
    "market_up = [\n",
    "    \"Hooray, you guys! The market finished up today. \",\n",
    "    \"Finance Duck is jazzed. Markets r up.\",\n",
    "    \"Capitalism won today. Markets finished higher.\",\n",
    "    \"Damn, son. Markets up.\",\n",
    "    \"\"\"\n",
    "            Adorable 4pm\n",
    "            A happy market high-fives\n",
    "            because of the ducks\n",
    "            \"\"\",\n",
    "    \"Tell your friends. Market is up. All is well.\",\n",
    "    \"If the markets aren't up, I'm a swan.\",\n",
    "    \"\"\"\n",
    "            gusting proudly, bulls\n",
    "            savor passionate nectars,\n",
    "            bears crying\"\"\",\n",
    "    \"yessir, markets are up.\",\n",
    "    \"I'm pumped. Markets are too.\",\n",
    "]\n",
    "\n",
    "market_down = [\n",
    "    \"Dang it. Markets wet the bed.\",\n",
    "    \"Whatever. I don't even care that the markets finished down.\",\n",
    "    \"Well I'll be a lune's uncle; the markets finished down.\",\n",
    "    \"Pfffft. Stupid markets. They finished (eider)down. Ohhhhhhhhh...\",\n",
    "    \"Nnnnggg, bahhhhh.\",\n",
    "    \"Snap. Markets down a bit.\",\n",
    "    \"\"\"\n",
    "            Dire evening\n",
    "            A dark, failing market descends\n",
    "            forget the duck.\"\"\",\n",
    "    \"Flapping heck. Market down.\",\n",
    "    \"My net worth is down. So is the market.\",\n",
    "]\n",
    "\n",
    "# Generate a Message Related to Where the Market Finished\n",
    "\n",
    "# First, we want to generate two options for contextual link sentences based on whether the first word of our article title is a verb or not.\n",
    "\n",
    "noun = \"My analysis concludes that it's because this \"\n",
    "verb = \"My analysis concludes that you should \"\n",
    "neither = \"My analysis concludes that it's because \"\n",
    "\n",
    "\n",
    "# Now we want to randomly select a duck message based on whether the market finished up or down.\n",
    "def duck_message(market_up, market_down, price_string):\n",
    "    up_message = random.choice(market_up)\n",
    "    down_message = random.choice(market_down)\n",
    "    if price_string[0] == \"+\":\n",
    "        return up_message\n",
    "    else:\n",
    "        return down_message\n",
    "\n",
    "\n",
    "duck_talk = duck_message(market_up, market_down, price_string)\n",
    "\n",
    "# Now we want to select a good article title and link to behave as the causal force in the market as identified by Finance Duck.\n",
    "\n",
    "\n",
    "def title_message(sentiment, title_list, price_string):\n",
    "    # grab the index numbers of the respective sentiments\n",
    "    pos_index = [i for i, x in enumerate(sentiment) if x == \"POSITIVE\"]\n",
    "    neg_index = [i for i, x in enumerate(sentiment) if x == \"NEGATIVE\"]\n",
    "    neut_index = [i for i, x in enumerate(sentiment) if x == \"NEUTRAL\"]\n",
    "    # if the market finished up select our random positive message; if there is no pos message, go with a neutral\n",
    "    if price_string[0] == \"+\":\n",
    "        if len(pos_index) > 0:\n",
    "            choice = random.choice(pos_index)\n",
    "            return choice, title_list[choice]\n",
    "        else:\n",
    "            choice = random.choice(neut_index)\n",
    "            return choice, title_list[choice]\n",
    "    # if it finished down but there are no negative sentiment stories today, use the neutral messages...\n",
    "    elif len(neg_index) == 0:\n",
    "        choice = random.choice(neut_index)\n",
    "        return choice, title_list[choice]\n",
    "    else:\n",
    "        choice = random.choice(neg_index)\n",
    "        return choice, title_list[choice]\n",
    "\n",
    "\n",
    "# otherwise stay on plan and use the negative sentiment title\n",
    "\n",
    "\n",
    "choice, title_result = title_message(sentiment, title_list, price_string)\n",
    "\n",
    "# Parse the title to see if the first word is a verb or noun\n",
    "first_word = client.detect_syntax(Text=title_result, LanguageCode=\"en\")[\"SyntaxTokens\"][0][\"PartOfSpeech\"][\"Tag\"]\n",
    "\n",
    "\n",
    "def link_phrase(first_word, verb, noun, neither):\n",
    "    if first_word == \"VERB\":\n",
    "        return verb\n",
    "    elif first_word == \"NOUN\":\n",
    "        return noun\n",
    "    else:\n",
    "        return neither\n",
    "\n",
    "\n",
    "anchor = link_phrase(first_word, verb, noun, neither)\n",
    "\n",
    "\"\"\"\n",
    "Link extraction from data frame. \n",
    "\"\"\"\n",
    "link = link_list[choice]\n",
    "\n",
    "\n",
    "# Compile the final message\n",
    "\n",
    "tweet = (\n",
    "    duck_talk\n",
    "    + \"\\n\\n\"\n",
    "    + \"The S&P500 closed at: \\n\"\n",
    "    + price_text\n",
    "    + anchor\n",
    "    + title_result\n",
    "    + \":\\n\"\n",
    "    + link\n",
    ")\n",
    "\n",
    "print(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting boto3\n",
      "  Downloading https://files.pythonhosted.org/packages/af/1d/833d463417f1ff84aeae42eb52795f4909cf54dbec62634e341080be5b0c/boto3-1.10.5-py2.py3-none-any.whl (128kB)\n",
      "Collecting s3transfer<0.3.0,>=0.2.0\n",
      "  Using cached https://files.pythonhosted.org/packages/16/8a/1fc3dba0c4923c2a76e1ff0d52b305c44606da63f718d14d3231e21c51b0/s3transfer-0.2.1-py2.py3-none-any.whl\n",
      "Collecting jmespath<1.0.0,>=0.7.1\n",
      "  Using cached https://files.pythonhosted.org/packages/83/94/7179c3832a6d45b266ddb2aac329e101367fbdb11f425f13771d27f225bb/jmespath-0.9.4-py2.py3-none-any.whl\n",
      "Collecting botocore<1.14.0,>=1.13.5\n",
      "  Downloading https://files.pythonhosted.org/packages/10/d8/f1fb1d6afe096fc7786187bea1a92fc7ebfec240ebd4d9ae8a36fc632e9a/botocore-1.13.5-py2.py3-none-any.whl (5.3MB)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in c:\\programdata\\anaconda3\\lib\\site-packages (from botocore<1.14.0,>=1.13.5->boto3) (0.15.2)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in c:\\programdata\\anaconda3\\lib\\site-packages (from botocore<1.14.0,>=1.13.5->boto3) (2.8.0)\n",
      "Requirement already satisfied: urllib3<1.26,>=1.20; python_version >= \"3.4\" in c:\\programdata\\anaconda3\\lib\\site-packages (from botocore<1.14.0,>=1.13.5->boto3) (1.25.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\"->botocore<1.14.0,>=1.13.5->boto3) (1.12.0)\n",
      "Installing collected packages: jmespath, botocore, s3transfer, boto3\n",
      "Successfully installed boto3-1.10.5 botocore-1.13.5 jmespath-0.9.4 s3transfer-0.2.1\n"
     ]
    }
   ],
   "source": [
    "import tweepy\n",
    "\n",
    "consumer_token = \"KPifY4hb2LIGRxN8XlFBSAv4A\"\n",
    "consumer_secret = \"43TiVgZ0NcM31K2Bpf634xnHfbD6CsVgunG3S3iM6Y03EKJVXV\"\n",
    "access_token = \"1142771823471468545-dzvFy7BFtzedUhQbukZqT9MVosf2JC\"\n",
    "access_secret = \"zohTzltTJOc4GBSAGqoV9uVGqInLZYISoFX9GqmC0VBVC\"\n",
    "\n",
    "auth = tweepy.OAuthHandler(consumer_token, consumer_secret)\n",
    "\n",
    "# Authenticate to Twitter\n",
    "auth = tweepy.OAuthHandler(consumer_token, consumer_secret)\n",
    "auth.set_access_token(access_token, access_secret)\n",
    "\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "# Tweet\n",
    "api.update_status(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.date(2019, 10, 30)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date.today()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(datetime.date(2019, 1, 1), \"New Year's Day\")\n",
      "(datetime.date(2019, 1, 21), 'Martin Luther King, Jr. Day')\n",
      "(datetime.date(2019, 2, 18), \"Washington's Birthday\")\n",
      "(datetime.date(2019, 5, 27), 'Memorial Day')\n",
      "(datetime.date(2019, 7, 4), 'Independence Day')\n",
      "(datetime.date(2019, 9, 2), 'Labor Day')\n",
      "(datetime.date(2019, 10, 14), 'Columbus Day')\n",
      "(datetime.date(2019, 11, 11), 'Veterans Day')\n",
      "(datetime.date(2019, 11, 28), 'Thanksgiving')\n",
      "(datetime.date(2019, 12, 25), 'Christmas Day')\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import holidays\n",
    "\n",
    "year = datetime.date.today().year\n",
    "hol_dict = holidays.UnitedStates(years=year).items()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'builtin_function_or_method' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-d346cac48a83>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mholidays\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mUnitedStates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0myears\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0myear\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'builtin_function_or_method' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "print(holidays.UnitedStates(years = year).items())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
